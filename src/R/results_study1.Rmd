---
title: Report on Results for Study 1
author: Jake Bowers
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document:
    number_sections: true
  html_document:
    number_sections: true
---



## The Design

We created a research design where pairs of survey respondents were created so as to be nearly identical on ideology. These pairs were also created so that the overall research design compared favorably with a pair-randomized experiment and otherwise produced extremely homogenous comparisons in terms of age, education, gender, race, partisanship, family income, and missingness on family income.

```{r}
library(here)
source(here("src", "R", "000_constants_and_utils.R"))
source(here("src/R", "rmd_setup.R"))
```


```{r}
library(kableExtra)
library(tidyverse)
library(estimatr)
library(coin)
library(sensemakr)
library(sensitivitymult)

load(file = here(MATCHES_DIR, "dat_plus_matches_study1.rda"), verbose = TRUE)
load(file = here(MATCHES_DIR, "outcome_analysis_study1.rda"))
```

Our design consists of `r nrow(dat3)` respondents from surveys 5--8 placed into pairs that were required to be the same on partisanship and survey. Is this a good research design for our question? Our main goal is to break the relationship between perceptions and potential confounders within pair --- that is, we aim to create pairs such that the person who, say, perceives more of their family wearing masks is no more or less likely to be the older member of the pair (or the democrat in the pair, or the more well-educated member of the pair, etc..). Within pair comparisons of perceptions in such a design then cannot be said to be confounded by the variables that we balanced.

We present a few pieces of information about our design here.

First, we show balance on average. The following table shows that the pairs have nearly the same mean values on the key covariates that we aim to balance.

```{r simpletab}
kable(tab[-nrow(tab), ])
```

What about within-pair differences? The following table tells us that across the `r nrow(dat3)/2` pairs, half differ by less than 1 point on the 5 point ideology scale, less than 1 point on the 6 point education scale, less than 3 years of age,  and more than half of the pairs were identical in gender and race. All pairs were identical in terms of the survey (since the surveys were fielded at different times). The worse differences we see are 2 points difference in ideology (for 10% of pairs) and less than 10% of pairs differed by as much as 5 years of age. From a substantive point of few, we suspect that these are quite small differences in substantive terms, and again, suggest that we have created a research design that limits the confounding effects of covariates on our targetted relationship.

```{r withinpairdiffs}

pd_means <- sapply(pair_diffs, mean, na.rm = TRUE)
pd_quants <- sapply(pair_diffs, function(x) {
  quantile(abs(x), probs = c(0, .1, .25, .5, .75, .9, 1), na.rm = TRUE)
})

pd_tab <- rbind(pd_quants, pd_means)

kableExtra::kable(pd_tab[, -c(1, 9)], digits = 3)
```

As a final check, we compare our design to an established standard: a pair-randomized experiment. If we were to randomize which member of a pair perceived more versus less mask wearing in their social network, we would expect no systematic relationships between perceptions and these covariates within pairs --- across many covariates, we would see some relationships, but if we were really to randomize, we would know exactly the distribution that these differences would take. This kind of firm knowledge of a standard for an unconfounded design suggests that we compare our non-randomized design to the equivalent randomized design in the process of arguing in favor of the design. Moreover @hansenbowers2008 showed that a single test can summarize the relationship between many covariates and a randomized intervention --- thus allowing us to avoid the multiple comparisons problem of looking at many different covariate tests.  That result for this design provides us with p=`r round(xbres$overall$p,2)` for the test of the hypothesis that the covariate-to-perception relationship is what we would observe in an experiment: that is, we have no strong argument against that null in this case. The subsequent table summarizes the variable-by-variable results. Again, we see that the person who is ranked as perceiving more positive health behaviors is no more or less likely to be older, etc.. That is, those covariates cannot strongly confound any comparisons we make within these pairs.


```{r balance}
xbres$overall
xbres_vars <- data.frame(xbres$results[, c("rankperc=0", "rankperc=1", "adj.diff", "std.diff", "p"), "matched"])
xbres_vars$padj <- p.adjust(xbres_vars$p, method = "holm")
kable(arrange(xbres_vars, p), digits = 3)
```


## Outcome Analysis

Our analysis of outcomes is quite simple: we regress reports of respondents' own intentions to be vaccinated, test, and wear masks on reports of those respondents' perception of such intentions in their social networks, conditional on pair. This amounts to comparing the own-intentions of the higher-perceiver within pair to the own-intentions of the lower-perceiver within pair and taking the average. We report HC2 standard errors.

I am just printing out the results here in raw form. First the scales of the variables to make interpretation easier:

```{r summaries}
somevars <- unique(c(
  all.vars(formula(lm_perc_fam)),
  all.vars(formula(lm_perc_neigh)),
  all.vars(formula(lm_perc_city)),
  all.vars(formula(lm_perc_state)),
  all.vars(formula(lm_mask_fam)),
  all.vars(formula(lm_test_fam))
))
```

```{r}
kableExtra::kable(summary(dat3[, somevars]))
```

Perceptions of vaccination intentions of others strongly predicts own intentions --- recall that we are very strongly holding constant ideology here.

```{r vaccinationintentions}
lm_perc_fam
lm_perc_neigh
lm_perc_city
lm_perc_state
```

Notice the pattern: family predicts more strongly than neighborhood, and in turn neighborhood than city, and city than state. Could we see this by chance? In fact, we have fairly strong evidence against arguments that this pattern of effects increasing with more personal relationships are just from chance. For example, using a seemingly unrelated regression framework, we tested hypotheses of equality among the coefficients shown above

```{r}
test_fam_vs_bigger
test_neigh_vs_bigger
test_city_vs_bigger
```


The social perceptions of the family to intentions relationship is not restricted to vaccination intentions. It also works for mask wearing and testing.

```{r masktestingintentions}
lm_mask_fam
lm_test_fam
```


# Sensitivity Analysis

This study was not randomized, but we are making statistical inferences as if it were --- as if perceptions were randomly assigned within these pairs. We know that we have some biases here, but are limited in regards our data. Although we have adjusted for some of the largest drivers of perceptions, we have not managed to control them all. How large of an unobserved effect on perceptions have to be in order to over turn our results? We present two modes of sensitivity analysis here.

## Hazlett and Cinelli

Our first approach builds on the approach in Cinelli and Hazlett in which they
posit a linear regression model and imagine unobserved confounders. They
propose a "Robustness Value" or a value of the influence of an unobserved
confounder on **both** the outcome and treatment above which our substantive
interpretation of our result would change. For example, we print out the
results for the effect of perceptions of family below. The key piece for us is
the `Robustness Value, q=1,alpha=.05`: this is the value above which we could
no longer claim to detect effects (the other values are more liberal --- values
that would be required to make our relationships exactly zero in magnitude).

```{r}
sens_perc_fam <- sensemakr(
  estimate = lm_perc_fam$coef["q60_1a"],
  se = lm_perc_fam$std.error["q60_1a"], dof = lm_perc_fam$df
)
summary(sens_perc_fam)
sens_perc_fam
```

So, we would need some covariates that are unrelated the variables included in
the pairing that would explain more than `r
round(100*sens_perc_fam$sensitivity_stats$rv_qa,1)`% of the variation in
**both** the outcome **and** perceptions in order for our statistical tests to
not-reject the null of no effects.

The other Robustness Values are displayed below.

All of the values are pretty large: what can we imagine that could predict
perceptions and vaccination intention independently of all of the variables in
the pairing as strongly as would be required below?

```{r}
get_rv_qa_value <- function(model) {
  res <- sensemakr(
    estimate = model$coef[1],
    se = lm_perc_fam$std.error[1], dof = lm_perc_fam$df
  )
  return(res$sensitivity_stats$rv_qa)
}

robustness_values <- sapply(ls(patt = "^lm_mask|^lm_perc|^lm_test"), function(lmname) {
  get_rv_qa_value(get(lmname))
})

sort(robustness_values, decreasing = TRUE)
```


## Rosenbaum Style

Paul Rosenbaum developed an approach to sensitivity analysis that Hazlett and Cinelli build on. It involves positing an unobserved factor that, within pair, changes the probability of "selection into treatment" away from uniform. Our "treatment" variable here has 7 categories, so we change the analysis a bit here: the question becomes whether the person who perceives more within a pair (rank of perceptions = 1) also tends to be the person with more positive vaccination intentions. In this formulation, if two people do not differ in perceptions, then this pair adds nothing to the analysis and they are dropped. The table below shows the estimates and p-values from a regression of outcomes on within-pair rank in perception.

```{r}
dat3 <- dat3 %>%
  group_by(bm) %>%
  mutate(
    q60_1a_rank = rank(q60_1a) - 1,
    q60_2a_rank = rank(q60_2a) - 1,
    q60_3a_rank = rank(q60_3a) - 1,
    q60_4a_rank = rank(q60_4a) - 1,
    q100_rank = rank(q100) - 1,
    q25_new_rank = rank(q25new) - 1
  ) %>%
  ungroup()

## Notice that sometimes the higher perceiver has a 1 and sometimes a 6 (mostly higher numbers of course).
with(dat3, table(q60_1a_rank, q60_1a, exclude = c()))

lm_perc_fam_rank <- lm_robust(q1 ~ q60_1a_rank, fixed_effects = ~bm, data = dat3)
lm_perc_neigh_rank <- lm_robust(q1 ~ q60_2a_rank, fixed_effects = ~bm, data = dat3)
lm_perc_city_rank <- lm_robust(q1 ~ q60_3a_rank, fixed_effects = ~bm, data = dat3)
lm_perc_state_rank <- lm_robust(q1 ~ q60_4a_rank, fixed_effects = ~bm, data = dat3)
lm_mask_fam_rank <- lm_robust(q7 ~ q100_rank, fixed_effects = ~bm, data = dat3)
lm_test_fam_rank <- lm_robust(q29 ~ q25_new_rank, fixed_effects = ~bm, data = dat3)

## These are just to help us understand the results below:
## the pattern of estimates and statistical tests should be the same as when we use the full scale
lm_rank_res_lst <- lapply(ls(patt = "_rank$"), function(lmnm) {
  res <- tidy(get(lmnm))
  res$model <- lmnm
  return(res)
})
lm_rank_res <- bind_rows(lm_rank_res_lst) %>%
  select(term, estimate, p.value, conf.low, conf.high, model, outcome) %>%
  mutate(across(where(is.numeric), round, 3))
lm_rank_res
```

```{r}
## here is the p-value with no bias
find_gamma_lim(g = 1, y = "q1", dat = dat3, z = "q60_1a_rank", return = "all")$pval
lm_perc_fam_rank ## notice basically same
## Now find the Gamma (or size of the selection effect) required to drive p>=.05
sens_perc_fam_G <- uniroot(f = find_gamma_lim, y = "q1", z = "q60_1a_rank", dat = dat3, lower = 1, upper = 20)
## Here is the Gamma value: the covariate has to cause the person to be 4 times more likely to be the higher perceiver within the same pair
sens_perc_fam_G$root
## Showing the the pvalue is .0501 in this case
find_gamma_lim(g = sens_perc_fam_G$root, y = "q1", z = "q60_1a_rank", dat = dat3, return = "all")$pval


## Now for the other variables
gamma_vals <- sapply(1:nrow(lm_rank_res), function(i) {
  message(lm_rank_res[i, "outcome"], " ", lm_rank_res[i, "term"])
  res_G <- try(uniroot(f = find_gamma_lim, y = lm_rank_res[i, "outcome"], z = lm_rank_res[i, "term"], dat = dat3, lower = 1, upper = 20))
  if (inherits(x = res_G, "try-error")) {
    res_G$root <- NA
  }
  return(res_G$root)
})
names(gamma_vals) <- lm_rank_res$term[1:nrow(lm_rank_res)]
sort(gamma_vals, decreasing = TRUE, na.last = TRUE)
```

Notice that the stronger the relationship, the larger the bias required to drive the p-value above .05. Strongest effect is family, for example.

This next is the Rosenbaum and Silber approach to interpreting sensitivity parameters. Notice that the basic gamma values assume a gigantic relationship with the outcome.

```{r}

amps <- lapply(gamma_vals, function(theg) {
  if (is.na(theg)) {
    return(NA)
  }
  message(theg)
  my_amplify(theg, lambda = seq(theg + .001, 10))
})
names(amps) <- names(gamma_vals)

amps
```

The p-value that we see for a given $\Gamma$ (like `r
gamma_vals[[1]]`)  can be produced from an unobserved covariate that
increases the treatment odds (within all pairs) by lambda and
increases the odds of a positive pair difference in outcomes by
delta.

## Auxiliary analyses

What if, in every pair, the person who reports that she perceives more
vaccination support among her family and friends, neighborhors, and people in
her city and state does so because she *hopes* that they will be vaccinated ---
that is, she herself believes vaccination is good, so she hopes that those
close to her will be vaccinated. This kind of wishful thinking or imagining a
consensus almost certainly does not occur in *every* pair, but yet, we wonder
in how many pairs we might see this phenomenon.  Notice that saying "no one
will vaccinate" for all levels and saying "everyone will vaccinate" at all
levels both indicates a kind of wishful thinking (either believing that
vaccination is bad and no one should do it, and believeing that it is good that
everyone should do it.) How many people exhibit this kind of response pattern?
Do people with these response patterns tend to also report either a stronglya
negative or positive own intention?  If few do, and this pattern does not
strongly predict own intention, then we have less concern about wishful
thinking driving our results.

Furthermore, we should note that this kind of false consensensus or reverse
causality would not necessarily imply the pattern of results that we see:
someone who is not actually reporting perceptions but hopes or rationalizations
is likely to project those to all groups, and not first to family and friends
(or most strongly to them) and then less strongly as the group becomes more
distant and diffuse.

We see here that very few people show this response pattern, too few to
overturn our results (considering the sensitivity analysis above). Also, notice
that those having this pattern are not perfectly homogenous in their own
intentions --- those reporting that all will definitely be vaccinated at all
levels are very likely to say that they will be vaccinated, and the converse is
also true, but this is not a perfect relationship.

```{r}

table(dat3$q60_1a, exclude = c())
table(dat3$q60_2a, exclude = c())
table(dat3$q60_3a, exclude = c())
table(dat3$q60_4a, exclude = c())

dat3 <- dat3 %>% mutate(
  perc_all_vax = as.numeric(q60_1a == 6 & q60_2a == 6 & q60_3a == 6 & q60_4a == 6),
  perc_none_vax = as.numeric(q60_1a == 0 & q60_2a == 0 & q60_3a == 0 & q60_4a == 0)
)

## Very few people have this response pattern:
with(dat3, table(perc_all_vax, exclude = c()))
with(dat3, table(perc_none_vax, exclude = c()))

with(dat3, table(perc_all_vax, q1, exclude = c()))
with(dat3, table(perc_none_vax, q1, exclude = c()))
```

# References
